{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Information Retrieval Codes with Explanation Practical 1 Practical 2 Practical 3 Practical 4 Practical 5 Practical 6 Practical 7 Practical 8 Viva Section General Viva ... More Coming Very Soon","title":"Home"},{"location":"#information-retrieval-codes-with-explanation","text":"","title":"Information Retrieval Codes with Explanation"},{"location":"#practical-1","text":"","title":"Practical 1"},{"location":"#practical-2","text":"","title":"Practical 2"},{"location":"#practical-3","text":"","title":"Practical 3"},{"location":"#practical-4","text":"","title":"Practical 4"},{"location":"#practical-5","text":"","title":"Practical 5"},{"location":"#practical-6","text":"","title":"Practical 6"},{"location":"#practical-7","text":"","title":"Practical 7"},{"location":"#practical-8","text":"","title":"Practical 8"},{"location":"#viva-section","text":"","title":"Viva Section"},{"location":"#general-viva","text":"... More Coming Very Soon","title":"General Viva"},{"location":"IRP2/","text":"Aim: Write a program to implement Page Rank Algorithm. \u2b07 We are importing networkx for creating a reference page rank order to which we can compare later. 1 import networkx as nx \u2b07 Numpy is a dependency of Matplotlib 1 import numpy as np \u2b07 Pandas is also imported for no reason \ud83d\ude15 1 import pandas as pd \u2b07 Matplotlib is a dependency of Networkx for the graph 1 import matplotlib.pyplot as plt \u2b07 Operator is also imported for no reason \ud83d\ude15 1 import operator \u2b07 Random is imported for generating random values 1 import random as rd \u2b07 nx.gnp_random_graph Returns a Gn,p random graph, also known as an Erd\u0151s-R\u00e9nyi graph or a binomial graph. The Gn,p model chooses each of the possible edges with probability p. here, 25 is the n or number of nodes 0.6 is the probability value directed=True will create a directed graph 1 graph = nx . gnp_random_graph ( 25 , 0.6 , directed = True ) \u2b07 nx.draw() Draws the graph G with Matplotlib. Draw the graph as a simple representation with no node labels or edge labels and using the full Matplotlib figure area and no axis labels by default. See draw_networkx() for more full-featured drawing that allows title, axis labels etc. G (graph): A networkx graph with_labels=True: (optional for label) font_color=\"white: (optional for font color) font_size=12: (optional for font size) node_color=\"purple\" (optional for node color) 1 2 nx . draw ( graph , with_labels = True , font_color = 'white' , font_size = 12 , node_color = 'purple' ) \u2b07 To plot the graph in a window we use plt.show() 1 plt . show () \u2b07 We are storing the count of nodes. 1 2 count = graph . number_of_nodes () print ( count ) 1 25 \u2b07 Listing the graph neighbors with degree 1 1 print ( list ( graph . neighbors ( 1 ))) 1 [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23] \u2b07 rank_dict for storing ranks 1 rank_dict = {} \u2b07 x is the random integer between 0 and 25 1 x = rd . randint ( 0 , 25 ) \u2b07 Here we are initializing rank_dict with 25(0-24) keys with 0 value 1 2 for j in range ( 0 , 25 ): rank_dict [ j ] = 0 \u2b07 we are adding 1 to the random x in dictionary 1 rank_dict [ x ] = rank_dict [ x ] + 1 \u2b07 Main Component of PageRank which computes the ranking of the nodes in the graph G based on the structure of the incoming links. we run this 5,00,000 times whenever the length of neighbours is 0 we randomly choose some other pivot as x otherwise we keep incrementing its rank. 1 2 3 4 5 6 7 8 9 10 for i in range ( 500000 ): list_n = list ( graph . neighbors ( x )) if ( len ( list_n ) == 0 ): x = rd . randint ( 0 , 25 ) rank_dict [ x ] = rank_dict [ x ] + 1 else : x = rd . choice ( list_n ) rank_dict [ x ] = rank_dict [ x ] + 1 print ( \"Random Walk Score Updated\" ) print ( rank_dict ) 1 2 Random Walk Score Updated {0: 26631, 1: 24160, 2: 21452, 3: 17846, 4: 14745, 5: 20613, 6: 14477, 7: 20485, 8: 17741, 9: 14687, 10: 22520, 11: 22676, 12: 23955, 13: 22945, 14: 18242, 15: 19426, 16: 21698, 17: 18471, 18: 22214, 19: 13605, 20: 28412, 21: 16974, 22: 18355, 23: 21216, 24: 16455} \u2b07 Here we are normalizing the values to get a value between 0-1 1 2 3 for j in range ( 0 , 25 ): rank_dict [ j ] = rank_dict [ j ] / 500000 print ( rank_dict ) 1 {0: 0.053262, 1: 0.04832, 2: 0.042904, 3: 0.035692, 4: 0.02949, 5: 0.041226, 6: 0.028954, 7: 0.04097, 8: 0.035482, 9: 0.029374, 10: 0.04504, 11: 0.045352, 12: 0.04791, 13: 0.04589, 14: 0.036484, 15: 0.038852, 16: 0.043396, 17: 0.036942, 18: 0.044428, 19: 0.02721, 20: 0.056824, 21: 0.033948, 22: 0.03671, 23: 0.042432, 24: 0.03291} \u2b07 nx.pagerank(): Returns the PageRank of the nodes in the graph. PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links. It was originally designed as an algorithm to rank web pages. 1 pagerank = nx . pagerank ( graph ) \u2b07 we are sorting the Networkx pageranked items 1 2 3 pagerank_sorted = sorted ( pagerank . items (), key = lambda v :( v [ 1 ], v [ 0 ]), reverse = True ) \u2b07 We are sorting our algorithm based ranked items 1 2 3 rank_dict_sorted = sorted ( rank_dict . items (), key = lambda v :( v [ 1 ], v [ 0 ]), reverse = True ) \u2b07 Finally comparing the outcomes 1 2 3 4 5 6 print ( \"The order generated by our implementation algorithm is \\n \" ) for i in rank_dict_sorted : print ( i [ 0 ], end = \" \" ) print ( \" \\n\\n The order generated by networkx library is \\n \" ) for i in pagerank_sorted : print ( i [ 0 ], end = \" \" ) 1 2 3 4 5 6 7 The order generated by our implementation algorithm is 20 0 1 12 13 11 10 18 16 2 23 5 7 15 17 22 14 3 8 21 24 4 9 6 19 The order generated by networkx library is 20 0 12 1 13 11 18 10 16 2 23 5 7 15 17 14 22 3 8 21 24 4 9 6 19","title":"Practical 2"},{"location":"IRP2/#aim-write-a-program-to-implement-page-rank-algorithm","text":"","title":"Aim: Write a program to implement Page Rank Algorithm."},{"location":"IRP2/#we-are-importing-networkx-for-creating-a-reference-page-rank-order-to-which-we-can-compare-later","text":"1 import networkx as nx","title":"\u2b07 We are importing networkx for creating a reference page rank order to which we can compare later."},{"location":"IRP2/#numpy-is-a-dependency-of-matplotlib","text":"1 import numpy as np","title":"\u2b07 Numpy is a dependency of Matplotlib"},{"location":"IRP2/#pandas-is-also-imported-for-no-reason","text":"1 import pandas as pd","title":"\u2b07 Pandas is also imported for no reason \ud83d\ude15"},{"location":"IRP2/#matplotlib-is-a-dependency-of-networkx-for-the-graph","text":"1 import matplotlib.pyplot as plt","title":"\u2b07 Matplotlib is a dependency of Networkx for the graph"},{"location":"IRP2/#operator-is-also-imported-for-no-reason","text":"1 import operator","title":"\u2b07 Operator is also imported for no reason \ud83d\ude15"},{"location":"IRP2/#random-is-imported-for-generating-random-values","text":"1 import random as rd","title":"\u2b07 Random is imported for generating random values"},{"location":"IRP2/#nxgnp_random_graph-returns-a-gnp-random-graph-also-known-as-an-erdos-renyi-graph-or-a-binomial-graph-the-gnp-model-chooses-each-of-the-possible-edges-with-probability-p","text":"here, 25 is the n or number of nodes 0.6 is the probability value directed=True will create a directed graph 1 graph = nx . gnp_random_graph ( 25 , 0.6 , directed = True )","title":"\u2b07 nx.gnp_random_graph Returns a Gn,p random graph, also known as an Erd\u0151s-R\u00e9nyi graph or a binomial graph. The Gn,p model chooses each of the possible edges with probability p."},{"location":"IRP2/#nxdraw-draws-the-graph-g-with-matplotlib","text":"Draw the graph as a simple representation with no node labels or edge labels and using the full Matplotlib figure area and no axis labels by default. See draw_networkx() for more full-featured drawing that allows title, axis labels etc. G (graph): A networkx graph with_labels=True: (optional for label) font_color=\"white: (optional for font color) font_size=12: (optional for font size) node_color=\"purple\" (optional for node color) 1 2 nx . draw ( graph , with_labels = True , font_color = 'white' , font_size = 12 , node_color = 'purple' )","title":"\u2b07 nx.draw() Draws the graph G with Matplotlib."},{"location":"IRP2/#to-plot-the-graph-in-a-window-we-use-pltshow","text":"1 plt . show ()","title":"\u2b07 To plot the graph in a window we use plt.show()"},{"location":"IRP2/#we-are-storing-the-count-of-nodes","text":"1 2 count = graph . number_of_nodes () print ( count ) 1 25","title":"\u2b07 We are storing the count of nodes."},{"location":"IRP2/#listing-the-graph-neighbors-with-degree-1","text":"1 print ( list ( graph . neighbors ( 1 ))) 1 [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23]","title":"\u2b07 Listing the graph neighbors with degree 1"},{"location":"IRP2/#rank_dict-for-storing-ranks","text":"1 rank_dict = {}","title":"\u2b07 rank_dict for storing ranks"},{"location":"IRP2/#x-is-the-random-integer-between-0-and-25","text":"1 x = rd . randint ( 0 , 25 )","title":"\u2b07 x is the random integer between 0 and 25"},{"location":"IRP2/#here-we-are-initializing-rank_dict-with-250-24-keys-with-0-value","text":"1 2 for j in range ( 0 , 25 ): rank_dict [ j ] = 0","title":"\u2b07 Here we are initializing rank_dict with 25(0-24) keys with 0 value"},{"location":"IRP2/#we-are-adding-1-to-the-random-x-in-dictionary","text":"1 rank_dict [ x ] = rank_dict [ x ] + 1","title":"\u2b07 we are adding 1 to the random x in dictionary"},{"location":"IRP2/#main-component-of-pagerank-which-computes-the-ranking-of-the-nodes-in-the-graph-g-based-on-the-structure-of-the-incoming-links-we-run-this-500000-times-whenever-the-length-of-neighbours-is-0-we-randomly-choose-some-other-pivot-as-x-otherwise-we-keep-incrementing-its-rank","text":"1 2 3 4 5 6 7 8 9 10 for i in range ( 500000 ): list_n = list ( graph . neighbors ( x )) if ( len ( list_n ) == 0 ): x = rd . randint ( 0 , 25 ) rank_dict [ x ] = rank_dict [ x ] + 1 else : x = rd . choice ( list_n ) rank_dict [ x ] = rank_dict [ x ] + 1 print ( \"Random Walk Score Updated\" ) print ( rank_dict ) 1 2 Random Walk Score Updated {0: 26631, 1: 24160, 2: 21452, 3: 17846, 4: 14745, 5: 20613, 6: 14477, 7: 20485, 8: 17741, 9: 14687, 10: 22520, 11: 22676, 12: 23955, 13: 22945, 14: 18242, 15: 19426, 16: 21698, 17: 18471, 18: 22214, 19: 13605, 20: 28412, 21: 16974, 22: 18355, 23: 21216, 24: 16455}","title":"\u2b07 Main Component of PageRank which computes the ranking of the nodes in the graph G based on the structure of the incoming links. we run this 5,00,000 times whenever the length of neighbours is 0 we randomly choose some other pivot as x otherwise we keep incrementing its rank."},{"location":"IRP2/#here-we-are-normalizing-the-values-to-get-a-value-between-0-1","text":"1 2 3 for j in range ( 0 , 25 ): rank_dict [ j ] = rank_dict [ j ] / 500000 print ( rank_dict ) 1 {0: 0.053262, 1: 0.04832, 2: 0.042904, 3: 0.035692, 4: 0.02949, 5: 0.041226, 6: 0.028954, 7: 0.04097, 8: 0.035482, 9: 0.029374, 10: 0.04504, 11: 0.045352, 12: 0.04791, 13: 0.04589, 14: 0.036484, 15: 0.038852, 16: 0.043396, 17: 0.036942, 18: 0.044428, 19: 0.02721, 20: 0.056824, 21: 0.033948, 22: 0.03671, 23: 0.042432, 24: 0.03291}","title":"\u2b07 Here we are normalizing the values to get a value between 0-1"},{"location":"IRP2/#nxpagerank","text":"Returns the PageRank of the nodes in the graph. PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links. It was originally designed as an algorithm to rank web pages. 1 pagerank = nx . pagerank ( graph )","title":"\u2b07 nx.pagerank():"},{"location":"IRP2/#we-are-sorting-the-networkx-pageranked-items","text":"1 2 3 pagerank_sorted = sorted ( pagerank . items (), key = lambda v :( v [ 1 ], v [ 0 ]), reverse = True )","title":"\u2b07 we are sorting the Networkx pageranked items"},{"location":"IRP2/#we-are-sorting-our-algorithm-based-ranked-items","text":"1 2 3 rank_dict_sorted = sorted ( rank_dict . items (), key = lambda v :( v [ 1 ], v [ 0 ]), reverse = True )","title":"\u2b07 We are sorting our algorithm based ranked items"},{"location":"IRP2/#finally-comparing-the-outcomes","text":"1 2 3 4 5 6 print ( \"The order generated by our implementation algorithm is \\n \" ) for i in rank_dict_sorted : print ( i [ 0 ], end = \" \" ) print ( \" \\n\\n The order generated by networkx library is \\n \" ) for i in pagerank_sorted : print ( i [ 0 ], end = \" \" ) 1 2 3 4 5 6 7 The order generated by our implementation algorithm is 20 0 1 12 13 11 10 18 16 2 23 5 7 15 17 22 14 3 8 21 24 4 9 6 19 The order generated by networkx library is 20 0 12 1 13 11 18 10 16 2 23 5 7 15 17 14 22 3 8 21 24 4 9 6 19","title":"\u2b07 Finally comparing the outcomes"},{"location":"IRP3/","text":"Aim: Implement Dynamic programming algorithm for computing the edit distance betweenstrings s1 and s2. (Hint. Levenshtein Distance) Code 1 \u2b07 creating a function to find Levenshtein distance between two strings based on the strings and their lengths 1 2 3 4 5 6 7 def dist ( X , m , Y , n ): if ( m == 0 ): return n if ( n == 0 ): return m cost = 0 if ( X [ m - 1 ] == Y [ n - 1 ]) else 1 return min ( dist ( X , m - 1 , Y , n ) + 1 , #Remove dist ( X , m , Y , n - 1 ) + 1 , #Insert dist ( X , m - 1 , Y , n - 1 ) + cost ) #Replace 1 X = \"python\" 1 Y = \"thons\" 1 2 print ( \"The Levenshtein distance is :\" , dist ( X , len ( X ), Y , len ( Y ))) 1 The Levenshtein distance is : 3 Code 2 \u2b07 Pyrix is imported to be used instead of python lists as it will create a beautiful square matrix in output 1 import pyrix as px \u2b07 EditDistance calculator function using matrices 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def editDistDP ( str1 , str2 ): m = len ( str1 ) n = len ( str2 ) dp = px . zeroMatrix ( nrow = m + 1 , ncol = n + 1 ) #dp=[[0 for x in range(n+1)] for x in range(m+1)] print ( \"Intital Matrix:\" ) print ( dp ) for i in range ( m + 1 ): for j in range ( n + 1 ): if i == 0 : dp [ i ][ j ] = j elif j == 0 : dp [ i ][ j ] = i elif str1 [ i - 1 ] == str2 [ j - 1 ]: dp [ i ][ j ] = dp [ i - 1 ][ j - 1 ] else : dp [ i ][ j ] = 1 + min ( dp [ i ][ j - 1 ], #Insert dp [ i - 1 ][ j ], #Remove dp [ i - 1 ][ j - 1 ]) # Replace print ( \"Final Matrix\" ) print ( dp ) return dp [ m ][ n ] 1 str1 = \"hello\" 1 str2 = \"yellow\" 1 print ( \"Distance between two strings is:\" , editDistDP ( str1 , str2 )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Intital Matrix: Matrix: [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] Dimensions :6x7 Final Matrix Matrix: [0, 1, 2, 3, 4, 5, 6] [1, 1, 2, 3, 4, 5, 6] [2, 2, 1, 2, 3, 4, 5] [3, 3, 2, 1, 2, 3, 4] [4, 4, 3, 2, 1, 2, 3] [5, 5, 4, 3, 2, 1, 2] Dimensions :6x7 Distance between two strings is: 2","title":"Practical 3"},{"location":"IRP3/#aim-implement-dynamic-programming-algorithm-for-computing-the-edit-distance-betweenstrings-s1-and-s2-hint-levenshtein-distance","text":"","title":"Aim: Implement Dynamic programming algorithm for computing the edit distance betweenstrings s1 and s2. (Hint. Levenshtein Distance)"},{"location":"IRP3/#code-1","text":"","title":"Code 1"},{"location":"IRP3/#creating-a-function-to-find-levenshtein-distance-between-two-strings-based-on-the-strings-and-their-lengths","text":"1 2 3 4 5 6 7 def dist ( X , m , Y , n ): if ( m == 0 ): return n if ( n == 0 ): return m cost = 0 if ( X [ m - 1 ] == Y [ n - 1 ]) else 1 return min ( dist ( X , m - 1 , Y , n ) + 1 , #Remove dist ( X , m , Y , n - 1 ) + 1 , #Insert dist ( X , m - 1 , Y , n - 1 ) + cost ) #Replace 1 X = \"python\" 1 Y = \"thons\" 1 2 print ( \"The Levenshtein distance is :\" , dist ( X , len ( X ), Y , len ( Y ))) 1 The Levenshtein distance is : 3","title":"\u2b07 creating a function to find Levenshtein distance between two strings based on the strings and their lengths"},{"location":"IRP3/#code-2","text":"","title":"Code 2"},{"location":"IRP3/#pyrix-is-imported-to-be-used-instead-of-python-lists-as-it-will-create-a-beautiful-square-matrix-in-output","text":"1 import pyrix as px","title":"\u2b07 Pyrix is imported to be used instead of python lists as it will create a beautiful square matrix in output"},{"location":"IRP3/#editdistance-calculator-function-using-matrices","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def editDistDP ( str1 , str2 ): m = len ( str1 ) n = len ( str2 ) dp = px . zeroMatrix ( nrow = m + 1 , ncol = n + 1 ) #dp=[[0 for x in range(n+1)] for x in range(m+1)] print ( \"Intital Matrix:\" ) print ( dp ) for i in range ( m + 1 ): for j in range ( n + 1 ): if i == 0 : dp [ i ][ j ] = j elif j == 0 : dp [ i ][ j ] = i elif str1 [ i - 1 ] == str2 [ j - 1 ]: dp [ i ][ j ] = dp [ i - 1 ][ j - 1 ] else : dp [ i ][ j ] = 1 + min ( dp [ i ][ j - 1 ], #Insert dp [ i - 1 ][ j ], #Remove dp [ i - 1 ][ j - 1 ]) # Replace print ( \"Final Matrix\" ) print ( dp ) return dp [ m ][ n ] 1 str1 = \"hello\" 1 str2 = \"yellow\" 1 print ( \"Distance between two strings is:\" , editDistDP ( str1 , str2 )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Intital Matrix: Matrix: [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0] Dimensions :6x7 Final Matrix Matrix: [0, 1, 2, 3, 4, 5, 6] [1, 1, 2, 3, 4, 5, 6] [2, 2, 1, 2, 3, 4, 5] [3, 3, 2, 1, 2, 3, 4] [4, 4, 3, 2, 1, 2, 3] [5, 5, 4, 3, 2, 1, 2] Dimensions :6x7 Distance between two strings is: 2","title":"\u2b07 EditDistance calculator function using matrices"},{"location":"IRP4/","text":"Aim : Write a program to Compute Similarity between two text documents STEP-1 : Reading Files \u2b07 Math is used for acos(),pi,sqrt() 1 import math \u2b07 string is used for ascii_uppercase,ascii_lowercase and punctuation 1 import string \u2b07 sys is used for exiting the application/script if read file fails 1 import sys \u2b07 A function to read files and handle exceptions 1 2 3 4 5 6 7 8 def read_file ( filename ): try : with open ( filename , 'r' ) as f : data = f . read () return data except IOError : print ( \"Error opening or reading input file: \" , filename ) sys . exit () \u2b07 translation table will contain translation data in ascii values 1 2 3 translation_table = str . maketrans ( string . punctuation + string . ascii_uppercase , \" \" * len ( string . punctuation ) + string . ascii_lowercase ) print ( translation_table ) 1 {33: 32, 34: 32, 35: 32, 36: 32, 37: 32, 38: 32, 39: 32, 40: 32, 41: 32, 42: 32, 43: 32, 44: 32, 45: 32, 46: 32, 47: 32, 58: 32, 59: 32, 60: 32, 61: 32, 62: 32, 63: 32, 64: 32, 91: 32, 92: 32, 93: 32, 94: 32, 95: 32, 96: 32, 123: 32, 124: 32, 125: 32, 126: 32, 65: 97, 66: 98, 67: 99, 68: 100, 69: 101, 70: 102, 71: 103, 72: 104, 73: 105, 74: 106, 75: 107, 76: 108, 77: 109, 78: 110, 79: 111, 80: 112, 81: 113, 82: 114, 83: 115, 84: 116, 85: 117, 86: 118, 87: 119, 88: 120, 89: 121, 90: 122} \u2b07 This function will create a word list from the text and translate it according to the table 1 2 3 4 5 6 def get_words_from_line_list ( text ): text = text . translate ( translation_table ) word_list = text . split () return word_list STEP-2 : Calculating Frequency \u2b07 This Function will count the frequency of each word and store it in a dictionary and return the dictionary as output 1 2 3 4 5 6 7 8 def count_frequency ( word_list ): D = {} for new_word in word_list : if new_word in D : D [ new_word ] = D [ new_word ] + 1 else : D [ new_word ] = 1 return D \u2b07 This function is just a wrapper function for the reading the file, generating word list and calculating frequency 1 2 3 4 5 6 7 8 9 def word_frequencies_for_file ( filename ): line_list = read_file ( filename ) word_list = get_words_from_line_list ( line_list ) freq_mapping = count_frequency ( word_list ) print ( \"File\" , filename , \":\" , ) print ( len ( line_list ), \"Charactars, \" , ) print ( len ( word_list ), \"words, \" , ) print ( len ( freq_mapping ), \"distinct words\" ) return freq_mapping STEP-3 : Dot-Product and Angle \u2b07 Dot Product will calculate dot product between the two dictionaries of frequency values and return it 1 2 3 4 5 6 def dotProduct ( D1 , D2 ): Sum = 0.0 for key in D1 : if key in D2 : Sum += ( D1 [ key ] * D2 [ key ]) return Sum \u2b07 Vector Angle will calculate the angle between the two documents using the dotProduct value 1 2 3 4 def vector_angle ( D1 , D2 ): numerator = dotProduct ( D1 , D2 ) denominator = math . sqrt ( dotProduct ( D1 , D1 ) * dotProduct ( D2 , D2 )) return math . acos ( numerator / denominator ) STEP-4 : Document Similarity \u2b07 This last function will get word frequencies for 2 files and get the vector angle between them 1 2 3 4 5 6 7 def documentSimilarity ( filename_1 , filename_2 ): sorted_word_list_1 = word_frequencies_for_file ( filename_1 ) sorted_word_list_2 = word_frequencies_for_file ( filename_2 ) distance = vector_angle ( sorted_word_list_1 , sorted_word_list_2 ) print ( \"The distance between the documents is:\" , round ( distance , 7 ), \"(radians) or \" , round (( distance * 180 / math . pi ), 7 ), \"(degrees)\" ) \u2b07 Here we are calling the function with the path of the two text files 1 documentSimilarity ( \"t1.txt\" , \"t2.txt\" ) 1 2 3 4 5 6 7 8 9 File t1.txt : 29 Charactars, 5 words, 5 distinct words File t2.txt : 12 Charactars, 2 words, 2 distinct words The distance between the documents is: 1.5707963 (radians) or 90.0 (degrees)","title":"Practical 4"},{"location":"IRP4/#aim-write-a-program-to-compute-similarity-between-two-text-documents","text":"","title":"Aim : Write a program to Compute Similarity between two text documents"},{"location":"IRP4/#step-1-reading-files","text":"","title":"STEP-1 : Reading Files"},{"location":"IRP4/#math-is-used-for-acospisqrt","text":"1 import math","title":"\u2b07 Math is used for acos(),pi,sqrt()"},{"location":"IRP4/#string-is-used-for-ascii_uppercaseascii_lowercase-and-punctuation","text":"1 import string","title":"\u2b07 string is used for ascii_uppercase,ascii_lowercase and punctuation"},{"location":"IRP4/#sys-is-used-for-exiting-the-applicationscript-if-read-file-fails","text":"1 import sys","title":"\u2b07 sys is used for exiting the application/script if read file fails"},{"location":"IRP4/#a-function-to-read-files-and-handle-exceptions","text":"1 2 3 4 5 6 7 8 def read_file ( filename ): try : with open ( filename , 'r' ) as f : data = f . read () return data except IOError : print ( \"Error opening or reading input file: \" , filename ) sys . exit ()","title":"\u2b07 A function to read files and handle exceptions"},{"location":"IRP4/#translation-table-will-contain-translation-data-in-ascii-values","text":"1 2 3 translation_table = str . maketrans ( string . punctuation + string . ascii_uppercase , \" \" * len ( string . punctuation ) + string . ascii_lowercase ) print ( translation_table ) 1 {33: 32, 34: 32, 35: 32, 36: 32, 37: 32, 38: 32, 39: 32, 40: 32, 41: 32, 42: 32, 43: 32, 44: 32, 45: 32, 46: 32, 47: 32, 58: 32, 59: 32, 60: 32, 61: 32, 62: 32, 63: 32, 64: 32, 91: 32, 92: 32, 93: 32, 94: 32, 95: 32, 96: 32, 123: 32, 124: 32, 125: 32, 126: 32, 65: 97, 66: 98, 67: 99, 68: 100, 69: 101, 70: 102, 71: 103, 72: 104, 73: 105, 74: 106, 75: 107, 76: 108, 77: 109, 78: 110, 79: 111, 80: 112, 81: 113, 82: 114, 83: 115, 84: 116, 85: 117, 86: 118, 87: 119, 88: 120, 89: 121, 90: 122}","title":"\u2b07 translation table will contain translation data in ascii values"},{"location":"IRP4/#this-function-will-create-a-word-list-from-the-text-and-translate-it-according-to-the-table","text":"1 2 3 4 5 6 def get_words_from_line_list ( text ): text = text . translate ( translation_table ) word_list = text . split () return word_list","title":"\u2b07 This function will create a word list from the text and translate it according to the table"},{"location":"IRP4/#step-2-calculating-frequency","text":"","title":"STEP-2 : Calculating Frequency"},{"location":"IRP4/#this-function-will-count-the-frequency-of-each-word-and-store-it-in-a-dictionary-and-return-the-dictionary-as-output","text":"1 2 3 4 5 6 7 8 def count_frequency ( word_list ): D = {} for new_word in word_list : if new_word in D : D [ new_word ] = D [ new_word ] + 1 else : D [ new_word ] = 1 return D","title":"\u2b07 This Function will count the frequency of each word and store it in a dictionary and return the dictionary as output"},{"location":"IRP4/#this-function-is-just-a-wrapper-function-for-the-reading-the-file-generating-word-list-and-calculating-frequency","text":"1 2 3 4 5 6 7 8 9 def word_frequencies_for_file ( filename ): line_list = read_file ( filename ) word_list = get_words_from_line_list ( line_list ) freq_mapping = count_frequency ( word_list ) print ( \"File\" , filename , \":\" , ) print ( len ( line_list ), \"Charactars, \" , ) print ( len ( word_list ), \"words, \" , ) print ( len ( freq_mapping ), \"distinct words\" ) return freq_mapping","title":"\u2b07 This function is just a wrapper function for the reading the file, generating word list and calculating frequency"},{"location":"IRP4/#step-3-dot-product-and-angle","text":"","title":"STEP-3 : Dot-Product and Angle"},{"location":"IRP4/#dot-product-will-calculate-dot-product-between-the-two-dictionaries-of-frequency-values-and-return-it","text":"1 2 3 4 5 6 def dotProduct ( D1 , D2 ): Sum = 0.0 for key in D1 : if key in D2 : Sum += ( D1 [ key ] * D2 [ key ]) return Sum","title":"\u2b07 Dot Product will calculate dot product between the two dictionaries of frequency values and return it"},{"location":"IRP4/#vector-angle-will-calculate-the-angle-between-the-two-documents-using-the-dotproduct-value","text":"1 2 3 4 def vector_angle ( D1 , D2 ): numerator = dotProduct ( D1 , D2 ) denominator = math . sqrt ( dotProduct ( D1 , D1 ) * dotProduct ( D2 , D2 )) return math . acos ( numerator / denominator )","title":"\u2b07 Vector Angle will calculate the angle between the two documents using the dotProduct value"},{"location":"IRP4/#step-4-document-similarity","text":"","title":"STEP-4 : Document Similarity"},{"location":"IRP4/#this-last-function-will-get-word-frequencies-for-2-files-and-get-the-vector-angle-between-them","text":"1 2 3 4 5 6 7 def documentSimilarity ( filename_1 , filename_2 ): sorted_word_list_1 = word_frequencies_for_file ( filename_1 ) sorted_word_list_2 = word_frequencies_for_file ( filename_2 ) distance = vector_angle ( sorted_word_list_1 , sorted_word_list_2 ) print ( \"The distance between the documents is:\" , round ( distance , 7 ), \"(radians) or \" , round (( distance * 180 / math . pi ), 7 ), \"(degrees)\" )","title":"\u2b07 This last function will get word frequencies for 2 files and get the vector angle between them"},{"location":"IRP4/#here-we-are-calling-the-function-with-the-path-of-the-two-text-files","text":"1 documentSimilarity ( \"t1.txt\" , \"t2.txt\" ) 1 2 3 4 5 6 7 8 9 File t1.txt : 29 Charactars, 5 words, 5 distinct words File t2.txt : 12 Charactars, 2 words, 2 distinct words The distance between the documents is: 1.5707963 (radians) or 90.0 (degrees)","title":"\u2b07 Here we are calling the function with the path of the two text files"},{"location":"IRP5/","text":"Aim : Write a program for Pre-processing of a Text Document: stop word removal. Installation of core modules 1 import nltk 1 nltk . download () 1 2 3 4 5 6 7 showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml True Code \u2b07 stopwords is used to get all the stopwords in english language 1 from nltk.corpus import stopwords \u2b07 word_tokenize uses punkt tokenizer for tokenizing english words in sentences or paragraphs 1 from nltk.tokenize import word_tokenize \u2b07 An example Sentence 1 sentence = \"I am Abhishek, who is performing an Information retrieval using the NLTK package.\" 1 print ( \"Original Sentence : \\n \" , sentence . lower ()) 1 2 Original Sentence : i am abhishek, who is performing an information retrieval using the nltk package. \u2b07 Creating a set of english stopwords 1 stop_words = set ( stopwords . words ( 'english' )) \u2b07 Printing all the stop words 1 print ( \"Stop Words in English are : \\n \" , stop_words ) 1 2 Stop Words in English are : {\"you're\", 'again', 'wasn', 'here', 'shouldn', 'their', 'will', 'having', 'wouldn', 'were', 'over', \"should've\", 'themselves', 'its', 'them', 'while', 'same', 'against', 'are', 'him', 'very', 'haven', \"wasn't\", 'with', 'such', 'these', \"didn't\", \"shan't\", 'below', 're', 'you', 've', 'myself', 'won', 'but', 'isn', 'about', 'hers', 'll', 's', 'so', 'my', 'itself', 'couldn', 'out', 'that', 'been', 'to', 'each', 'ma', 'more', 'some', \"shouldn't\", 'he', 'there', 'have', 'his', 'then', \"that'll\", 'do', \"you'll\", 'theirs', 'when', 'weren', 'because', \"haven't\", 'she', 'up', \"weren't\", 'ours', 'which', 'through', \"wouldn't\", 'both', 'be', 'whom', 'and', \"it's\", 'during', \"isn't\", 'this', 'nor', 'now', 'm', 'a', 'yours', 'hasn', 'did', 'before', 'has', \"needn't\", 'being', 'from', 'as', 'once', 'no', 'if', 'what', 'for', 'ain', 'shan', \"you'd\", 'ourselves', 'himself', 'o', 'can', 'or', 'mustn', \"hasn't\", 'needn', 'doing', 'of', 'on', \"you've\", 'hadn', 'all', 'the', 'yourselves', 'herself', 'it', 'off', 'our', 'between', \"won't\", 'above', 'those', 'don', 'y', 'mightn', 'further', 'd', 'until', 'aren', \"mightn't\", \"couldn't\", 'own', 'they', 'too', 'down', 'in', 'her', 'is', 'your', 'only', 'how', \"aren't\", 'we', 'at', 'after', 'an', 'me', \"don't\", 'most', 'other', 'should', 'into', 'who', \"hadn't\", 'any', 'had', 'i', 'was', 'am', 'under', 'just', 'yourself', 'than', 'does', \"mustn't\", 'why', 't', 'by', 'few', \"she's\", 'didn', 'where', \"doesn't\", 'not', 'doesn'} \u2b07 Creating a list of tokenized words from the sentence 1 word_tokens = word_tokenize ( sentence ) 1 print ( \"After Tokenization : \\n \" , word_tokens ) 1 2 After Tokenization : ['I', 'am', 'Abhishek', ',', 'who', 'is', 'performing', 'an', 'Information', 'retrieval', 'using', 'the', 'NLTK', 'package', '.'] \u2b07 A list variable for the filtered words from the sentence 1 filt_sentence = [] \u2b07 adding the non stop words into the filtered sentence list 1 2 3 for w in word_tokens : if w not in stop_words : filt_sentence . append ( w ) 1 print ( \"Filtered Sentence after removing stop-words : \\n \" , ' ' . join ( filt_sentence )) 1 2 Filtered Sentence after removing stop-words : I Abhishek , performing Information retrieval using NLTK package . 1 print ( \"The Length of stop words is :\" , len ( stop_words )) 1 The Length of stop words is : 179 1 print ( \"The Length of orignal sentence is :\" , len ( sentence )) 1 The Length of orignal sentence is : 81","title":"Practical 5"},{"location":"IRP5/#aim-write-a-program-for-pre-processing-of-a-text-document-stop-word-removal","text":"","title":"Aim : Write a program for Pre-processing of a Text Document: stop word removal."},{"location":"IRP5/#installation-of-core-modules","text":"1 import nltk 1 nltk . download () 1 2 3 4 5 6 7 showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml True","title":"Installation of core modules"},{"location":"IRP5/#code","text":"","title":"Code"},{"location":"IRP5/#stopwords-is-used-to-get-all-the-stopwords-in-english-language","text":"1 from nltk.corpus import stopwords","title":"\u2b07 stopwords is used to get all the stopwords in english language"},{"location":"IRP5/#word_tokenize-uses-punkt-tokenizer-for-tokenizing-english-words-in-sentences-or-paragraphs","text":"1 from nltk.tokenize import word_tokenize","title":"\u2b07 word_tokenize uses punkt tokenizer for tokenizing english words in sentences or paragraphs"},{"location":"IRP5/#an-example-sentence","text":"1 sentence = \"I am Abhishek, who is performing an Information retrieval using the NLTK package.\" 1 print ( \"Original Sentence : \\n \" , sentence . lower ()) 1 2 Original Sentence : i am abhishek, who is performing an information retrieval using the nltk package.","title":"\u2b07 An example Sentence"},{"location":"IRP5/#creating-a-set-of-english-stopwords","text":"1 stop_words = set ( stopwords . words ( 'english' ))","title":"\u2b07 Creating a set of english stopwords"},{"location":"IRP5/#printing-all-the-stop-words","text":"1 print ( \"Stop Words in English are : \\n \" , stop_words ) 1 2 Stop Words in English are : {\"you're\", 'again', 'wasn', 'here', 'shouldn', 'their', 'will', 'having', 'wouldn', 'were', 'over', \"should've\", 'themselves', 'its', 'them', 'while', 'same', 'against', 'are', 'him', 'very', 'haven', \"wasn't\", 'with', 'such', 'these', \"didn't\", \"shan't\", 'below', 're', 'you', 've', 'myself', 'won', 'but', 'isn', 'about', 'hers', 'll', 's', 'so', 'my', 'itself', 'couldn', 'out', 'that', 'been', 'to', 'each', 'ma', 'more', 'some', \"shouldn't\", 'he', 'there', 'have', 'his', 'then', \"that'll\", 'do', \"you'll\", 'theirs', 'when', 'weren', 'because', \"haven't\", 'she', 'up', \"weren't\", 'ours', 'which', 'through', \"wouldn't\", 'both', 'be', 'whom', 'and', \"it's\", 'during', \"isn't\", 'this', 'nor', 'now', 'm', 'a', 'yours', 'hasn', 'did', 'before', 'has', \"needn't\", 'being', 'from', 'as', 'once', 'no', 'if', 'what', 'for', 'ain', 'shan', \"you'd\", 'ourselves', 'himself', 'o', 'can', 'or', 'mustn', \"hasn't\", 'needn', 'doing', 'of', 'on', \"you've\", 'hadn', 'all', 'the', 'yourselves', 'herself', 'it', 'off', 'our', 'between', \"won't\", 'above', 'those', 'don', 'y', 'mightn', 'further', 'd', 'until', 'aren', \"mightn't\", \"couldn't\", 'own', 'they', 'too', 'down', 'in', 'her', 'is', 'your', 'only', 'how', \"aren't\", 'we', 'at', 'after', 'an', 'me', \"don't\", 'most', 'other', 'should', 'into', 'who', \"hadn't\", 'any', 'had', 'i', 'was', 'am', 'under', 'just', 'yourself', 'than', 'does', \"mustn't\", 'why', 't', 'by', 'few', \"she's\", 'didn', 'where', \"doesn't\", 'not', 'doesn'}","title":"\u2b07 Printing all the stop words"},{"location":"IRP5/#creating-a-list-of-tokenized-words-from-the-sentence","text":"1 word_tokens = word_tokenize ( sentence ) 1 print ( \"After Tokenization : \\n \" , word_tokens ) 1 2 After Tokenization : ['I', 'am', 'Abhishek', ',', 'who', 'is', 'performing', 'an', 'Information', 'retrieval', 'using', 'the', 'NLTK', 'package', '.']","title":"\u2b07 Creating a list of tokenized words from the sentence"},{"location":"IRP5/#a-list-variable-for-the-filtered-words-from-the-sentence","text":"1 filt_sentence = []","title":"\u2b07 A list variable for the filtered words from the sentence"},{"location":"IRP5/#adding-the-non-stop-words-into-the-filtered-sentence-list","text":"1 2 3 for w in word_tokens : if w not in stop_words : filt_sentence . append ( w ) 1 print ( \"Filtered Sentence after removing stop-words : \\n \" , ' ' . join ( filt_sentence )) 1 2 Filtered Sentence after removing stop-words : I Abhishek , performing Information retrieval using NLTK package . 1 print ( \"The Length of stop words is :\" , len ( stop_words )) 1 The Length of stop words is : 179 1 print ( \"The Length of orignal sentence is :\" , len ( sentence )) 1 The Length of orignal sentence is : 81","title":"\u2b07 adding the non stop words into the filtered sentence list"},{"location":"IRP6/","text":"Aim : Write a program to implement simple web crawler. \u2b07 We are using requests package to get our webpage as HTML 1 import requests \u2b07 Beautiful Soup is a Python library for pulling data out of HTML and XML files 1 from bs4 import BeautifulSoup \u2b07 This function will parse all the data from the URL if it is a valid one 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def crawlerWeb ( WebURL ): if WebURL : print ( \"Url found!\" ) plain = requests . get ( WebURL ) . text s = BeautifulSoup ( plain , \"html.parser\" ) print ( \"The number of occurences of 'a' tag are:\" ) for link in s . findAll ( 'a' ,): # Finds all <a> tags tet = link . get ( 'title' ) print ( \"Title of item:-\" , tet ) tet2 = link . get ( 'href' ) print ( \"The URL visited:-\" , tet2 ) print ( \"The occurences of 'tr' tag are\" ) for link2 in s . find_all ( 'tr' ): # Finds all <tr> tags print ( link2 . get_text ()) print ( \"The occurences and parent tag of 'link' are:\" ) for link3 in s . find_all ( 'link' ): # Finds all <link> tags print ( link3 . parent . name ) count = 0 for i in s . find_all ( 'div' ): # Finds all <div> tags count = count + 1 print ( \"The div is occuring for\" , count ) print ( \"The occurences of parent of 'head' tag is:\" ) for link3 in s . findAll ( 'head' ): # Finds all <head> tags print ( link3 . parent . name ) \u2b07 Calling the crawler function on our sample website 1 crawlerWeb ( 'http://thedemosite.co.uk/addauser.php' ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 Url found! The number of occurences of 'a' tag are: Title of item:- None The URL visited:- https://thedemosite.co.uk/ Title of item:- None The URL visited:- https://thedemosite.co.uk/phpformmailer/ Title of item:- None The URL visited:- index.php Title of item:- None The URL visited:- thedatabase.php Title of item:- None The URL visited:- addauser.php Title of item:- None The URL visited:- login.php Title of item:- None The URL visited:- getyourowndbonline.php Title of item:- None The URL visited:- javascript:alert('The username must be between 4 and 16 characters long.') Title of item:- None The URL visited:- javascript:alert('The password must be between 4 and 8 characters long.') Title of item:- None The URL visited:- javascript:alert('Click to save the details') Title of item:- None The URL visited:- login.php Title of item:- None The URL visited:- addausercode.php Title of item:- None The URL visited:- demo-code.zip Title of item:- None The URL visited:- http://www.seiretto.com/web_hosting/reseller_hosting.php Title of item:- None The URL visited:- http://www.AcHost.co.uk/ Title of item:- None The URL visited:- http://www.govhost.uk/ Title of item:- None The URL visited:- https://www.seiretto.co.uk/ Title of item:- None The URL visited:- http://thedemosite.co.uk/ Title of item:- None The URL visited:- http://thedemosite.co.uk/phpformmailer/ The occurences of 'tr' tag are PHP and MySQLsample code Just examples of PHP code, linking to your MySQL database and JavaScript. 1. Home | 2. The Database | 3. Add a User | 4. Login | 5. Get your db online PHP and MySQLsample code Just examples of PHP code, linking to your MySQL database and JavaScript. 1. Home | 2. The Database | 3. Add a User | 4. Login | 5. Get your db online All code updated April 2014, now uses PHP/PDO for database connectivity Warning: Your Internet Browser has JavaScript switched off or is an older browser. You will not be able to complete this form. Please switch on JavaScript or return with a newer browser. 3. Add a User Add Your test username: Help Add Your test password: Help Help When you have added your own username and password move onto the Login page to test it! Add Your test username: Help Add Your test password: Help Help UK reseller hosting start your own web reseller business Seiretto.com AC.UK web hosting UK academic domain names and web hostingAcHost.co.uk The occurences and parent tag of 'link' are: head The div is occuring for 8 The occurences of parent of 'head' tag is: html 1","title":"Practical 6"},{"location":"IRP6/#aim-write-a-program-to-implement-simple-web-crawler","text":"","title":"Aim : Write a program to implement simple web crawler."},{"location":"IRP6/#we-are-using-requests-package-to-get-our-webpage-as-html","text":"1 import requests","title":"\u2b07 We are using requests package to get our webpage as HTML"},{"location":"IRP6/#beautiful-soup-is-a-python-library-for-pulling-data-out-of-html-and-xml-files","text":"1 from bs4 import BeautifulSoup","title":"\u2b07 Beautiful Soup is a Python library for pulling data out of HTML and XML files"},{"location":"IRP6/#this-function-will-parse-all-the-data-from-the-url-if-it-is-a-valid-one","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def crawlerWeb ( WebURL ): if WebURL : print ( \"Url found!\" ) plain = requests . get ( WebURL ) . text s = BeautifulSoup ( plain , \"html.parser\" ) print ( \"The number of occurences of 'a' tag are:\" ) for link in s . findAll ( 'a' ,): # Finds all <a> tags tet = link . get ( 'title' ) print ( \"Title of item:-\" , tet ) tet2 = link . get ( 'href' ) print ( \"The URL visited:-\" , tet2 ) print ( \"The occurences of 'tr' tag are\" ) for link2 in s . find_all ( 'tr' ): # Finds all <tr> tags print ( link2 . get_text ()) print ( \"The occurences and parent tag of 'link' are:\" ) for link3 in s . find_all ( 'link' ): # Finds all <link> tags print ( link3 . parent . name ) count = 0 for i in s . find_all ( 'div' ): # Finds all <div> tags count = count + 1 print ( \"The div is occuring for\" , count ) print ( \"The occurences of parent of 'head' tag is:\" ) for link3 in s . findAll ( 'head' ): # Finds all <head> tags print ( link3 . parent . name )","title":"\u2b07 This function will parse all the data from the URL if it is a valid one"},{"location":"IRP6/#calling-the-crawler-function-on-our-sample-website","text":"1 crawlerWeb ( 'http://thedemosite.co.uk/addauser.php' ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 Url found! The number of occurences of 'a' tag are: Title of item:- None The URL visited:- https://thedemosite.co.uk/ Title of item:- None The URL visited:- https://thedemosite.co.uk/phpformmailer/ Title of item:- None The URL visited:- index.php Title of item:- None The URL visited:- thedatabase.php Title of item:- None The URL visited:- addauser.php Title of item:- None The URL visited:- login.php Title of item:- None The URL visited:- getyourowndbonline.php Title of item:- None The URL visited:- javascript:alert('The username must be between 4 and 16 characters long.') Title of item:- None The URL visited:- javascript:alert('The password must be between 4 and 8 characters long.') Title of item:- None The URL visited:- javascript:alert('Click to save the details') Title of item:- None The URL visited:- login.php Title of item:- None The URL visited:- addausercode.php Title of item:- None The URL visited:- demo-code.zip Title of item:- None The URL visited:- http://www.seiretto.com/web_hosting/reseller_hosting.php Title of item:- None The URL visited:- http://www.AcHost.co.uk/ Title of item:- None The URL visited:- http://www.govhost.uk/ Title of item:- None The URL visited:- https://www.seiretto.co.uk/ Title of item:- None The URL visited:- http://thedemosite.co.uk/ Title of item:- None The URL visited:- http://thedemosite.co.uk/phpformmailer/ The occurences of 'tr' tag are PHP and MySQLsample code Just examples of PHP code, linking to your MySQL database and JavaScript. 1. Home | 2. The Database | 3. Add a User | 4. Login | 5. Get your db online PHP and MySQLsample code Just examples of PHP code, linking to your MySQL database and JavaScript. 1. Home | 2. The Database | 3. Add a User | 4. Login | 5. Get your db online All code updated April 2014, now uses PHP/PDO for database connectivity Warning: Your Internet Browser has JavaScript switched off or is an older browser. You will not be able to complete this form. Please switch on JavaScript or return with a newer browser. 3. Add a User Add Your test username: Help Add Your test password: Help Help When you have added your own username and password move onto the Login page to test it! Add Your test username: Help Add Your test password: Help Help UK reseller hosting start your own web reseller business Seiretto.com AC.UK web hosting UK academic domain names and web hostingAcHost.co.uk The occurences and parent tag of 'link' are: head The div is occuring for 8 The occurences of parent of 'head' tag is: html 1","title":"\u2b07 Calling the crawler function on our sample website"},{"location":"IRP7/","text":"Aim : Write a program to parse XML text \u2b07 We import this sub-package for parsing XML documents 1 import xml.etree.ElementTree as ET \u2b07 We import this package for creating and writing csv files 1 import csv \u2b07 Here we are parsing the menu.xml or any other xml file and storing its contents in tree variable 1 tree = ET . parse ( 'menu.xml' ) \u2b07 Get root will get the main XML Element or tag 1 root = tree . getroot () \u2b07 here we are opening a writer object for the csv file 1 menu_data = open ( 'menu.csv' , 'w' ) \u2b07 Here we pass the writer object to csv writer to write any subsequent data 1 csvwriter = csv . writer ( menu_data ) \u2b07 menu_head contains all the headings of csv file 1 menu_head = [] \u2b07 Initializing count to 0 1 count = 0 \u2b07 Here we read the xml file and in similar fashion add the data to the csv file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 for member in root . findall ( 'food' ): fooditem = [] if count == 0 : name = member . find ( 'name' ) . tag menu_head . append ( name ) price = member . find ( 'price' ) . tag menu_head . append ( price ) description = member . find ( 'description' ) . tag menu_head . append ( description ) calories = member . find ( 'calories' ) . tag menu_head . append ( calories ) csvwriter . writerow ( menu_head ) count = count + 1 fooditem . clear () name = member . find ( 'name' ) . text fooditem . append ( name ) price = member . find ( 'price' ) . text fooditem . append ( price ) description = member . find ( 'description' ) . text fooditem . append ( description ) calories = member . find ( 'calories' ) . text fooditem . append ( calories ) csvwriter . writerow ( fooditem ) count = count + 1 \u2b07 we close the data writer object 1 menu_data . close () Code 2 \u2b07 We import this sub-package for parsing XML documents 1 import xml.etree.ElementTree as ET \u2b07 Here we are parsing the menu.xml or any other xml file and storing its contents in tree variable 1 mytree = ET . parse ( 'sample.xml' ) \u2b07 Get root will get the main XML Element or tag 1 myroot = mytree . getroot () \u2b07 Printing the main Root 1 print ( myroot ) 1 <Element 'breakfast_menu' at 0x7f619852b5e8> \u2b07 Printing the first tag 1 print ( myroot [ 0 ] . tag ) 1 food \u2b07 Printing the root tags attributes 1 print ( myroot . attrib ) 1 {} \u2b07 Printing attributes of other tag in the first tag within root 1 2 for x in myroot [ 0 ]: print ( x . tag , x . attrib ) 1 2 3 4 name {'class': 'breakfast'} price {} description {} calories {} \u2b07 Printing text values of the nested tags 1 2 for x in myroot [ 0 ]: print ( x . text ) 1 2 3 4 Belgian Waffles $5.95 Two of our famous Belgian Waffles with plenty of real maple syrup 650 \u2b07 Here we modify the xml file and set a new attribute to each of the < description > tag 1 2 3 4 5 # Modifying XML for description in myroot . iter ( 'description' ): new_desc = str ( description . text ) + ' will be served' description . text = str ( new_desc ) description . set ( 'updated' , 'yes' ) \u2b07 Here we write the changes to a new XML file 1 mytree . write ( 'new.xml' ) \u2b07 Here we add a new tag itself to the first < food > item 1 2 3 4 5 #Adding Sub Tag ET . SubElement ( myroot [ 0 ], 'speciality' ) for x in myroot . iter ( 'speciality' ): new_desc = 'Continental Dish' x . text = str ( new_desc ) \u2b07 Here we write the changes to a new XML file 1 mytree . write ( 'output5.xml' )","title":"Practical 7"},{"location":"IRP7/#aim-write-a-program-to-parse-xml-text","text":"","title":"Aim : Write a program to parse XML text"},{"location":"IRP7/#we-import-this-sub-package-for-parsing-xml-documents","text":"1 import xml.etree.ElementTree as ET","title":"\u2b07 We import this sub-package for parsing XML documents"},{"location":"IRP7/#we-import-this-package-for-creating-and-writing-csv-files","text":"1 import csv","title":"\u2b07 We import this package for creating and writing csv files"},{"location":"IRP7/#here-we-are-parsing-the-menuxml-or-any-other-xml-file-and-storing-its-contents-in-tree-variable","text":"1 tree = ET . parse ( 'menu.xml' )","title":"\u2b07 Here we are parsing the menu.xml or any other xml file and storing its contents in tree variable"},{"location":"IRP7/#get-root-will-get-the-main-xml-element-or-tag","text":"1 root = tree . getroot ()","title":"\u2b07 Get root will get the main XML Element or tag"},{"location":"IRP7/#here-we-are-opening-a-writer-object-for-the-csv-file","text":"1 menu_data = open ( 'menu.csv' , 'w' )","title":"\u2b07 here we are opening a writer object for the csv file"},{"location":"IRP7/#here-we-pass-the-writer-object-to-csv-writer-to-write-any-subsequent-data","text":"1 csvwriter = csv . writer ( menu_data )","title":"\u2b07 Here we pass the writer object to csv writer to write any subsequent data"},{"location":"IRP7/#menu_head-contains-all-the-headings-of-csv-file","text":"1 menu_head = []","title":"\u2b07 menu_head contains all the headings of csv file"},{"location":"IRP7/#initializing-count-to-0","text":"1 count = 0","title":"\u2b07 Initializing count to 0"},{"location":"IRP7/#here-we-read-the-xml-file-and-in-similar-fashion-add-the-data-to-the-csv-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 for member in root . findall ( 'food' ): fooditem = [] if count == 0 : name = member . find ( 'name' ) . tag menu_head . append ( name ) price = member . find ( 'price' ) . tag menu_head . append ( price ) description = member . find ( 'description' ) . tag menu_head . append ( description ) calories = member . find ( 'calories' ) . tag menu_head . append ( calories ) csvwriter . writerow ( menu_head ) count = count + 1 fooditem . clear () name = member . find ( 'name' ) . text fooditem . append ( name ) price = member . find ( 'price' ) . text fooditem . append ( price ) description = member . find ( 'description' ) . text fooditem . append ( description ) calories = member . find ( 'calories' ) . text fooditem . append ( calories ) csvwriter . writerow ( fooditem ) count = count + 1","title":"\u2b07 Here we read the xml file and in similar fashion add the data to the csv file"},{"location":"IRP7/#we-close-the-data-writer-object","text":"1 menu_data . close ()","title":"\u2b07 we close the data writer object"},{"location":"IRP7/#code-2","text":"","title":"Code 2"},{"location":"IRP7/#we-import-this-sub-package-for-parsing-xml-documents_1","text":"1 import xml.etree.ElementTree as ET","title":"\u2b07 We import this sub-package for parsing XML documents"},{"location":"IRP7/#here-we-are-parsing-the-menuxml-or-any-other-xml-file-and-storing-its-contents-in-tree-variable_1","text":"1 mytree = ET . parse ( 'sample.xml' )","title":"\u2b07 Here we are parsing the menu.xml or any other xml file and storing its contents in tree variable"},{"location":"IRP7/#get-root-will-get-the-main-xml-element-or-tag_1","text":"1 myroot = mytree . getroot ()","title":"\u2b07 Get root will get the main XML Element or tag"},{"location":"IRP7/#printing-the-main-root","text":"1 print ( myroot ) 1 <Element 'breakfast_menu' at 0x7f619852b5e8>","title":"\u2b07 Printing the main Root"},{"location":"IRP7/#printing-the-first-tag","text":"1 print ( myroot [ 0 ] . tag ) 1 food","title":"\u2b07 Printing the first tag"},{"location":"IRP7/#printing-the-root-tags-attributes","text":"1 print ( myroot . attrib ) 1 {}","title":"\u2b07 Printing the root tags attributes"},{"location":"IRP7/#printing-attributes-of-other-tag-in-the-first-tag-within-root","text":"1 2 for x in myroot [ 0 ]: print ( x . tag , x . attrib ) 1 2 3 4 name {'class': 'breakfast'} price {} description {} calories {}","title":"\u2b07 Printing attributes of other tag in the first tag within root"},{"location":"IRP7/#printing-text-values-of-the-nested-tags","text":"1 2 for x in myroot [ 0 ]: print ( x . text ) 1 2 3 4 Belgian Waffles $5.95 Two of our famous Belgian Waffles with plenty of real maple syrup 650","title":"\u2b07 Printing text values of the nested tags"},{"location":"IRP7/#here-we-modify-the-xml-file-and-set-a-new-attribute-to-each-of-the-description-tag","text":"1 2 3 4 5 # Modifying XML for description in myroot . iter ( 'description' ): new_desc = str ( description . text ) + ' will be served' description . text = str ( new_desc ) description . set ( 'updated' , 'yes' )","title":"\u2b07 Here we modify the xml file and set a new attribute to each of the &lt; description &gt; tag"},{"location":"IRP7/#here-we-write-the-changes-to-a-new-xml-file","text":"1 mytree . write ( 'new.xml' )","title":"\u2b07 Here we write the changes to a new XML file"},{"location":"IRP7/#here-we-add-a-new-tag-itself-to-the-first-food-item","text":"1 2 3 4 5 #Adding Sub Tag ET . SubElement ( myroot [ 0 ], 'speciality' ) for x in myroot . iter ( 'speciality' ): new_desc = 'Continental Dish' x . text = str ( new_desc )","title":"\u2b07 Here we add a new tag itself to the first &lt; food &gt; item"},{"location":"IRP7/#here-we-write-the-changes-to-a-new-xml-file_1","text":"1 mytree . write ( 'output5.xml' )","title":"\u2b07 Here we write the changes to a new XML file"},{"location":"IRP8/","text":"Aim : Write a program for mining Twitter to identify tweets for a specific period and identify trends and named entities \u2b07 Importing tweepy to work with Twitter APIs 1 import tweepy \ud83d\udc47 Regenerate your token and paste here 1 access_token = \"<Your Access_Token will come here>\" \ud83d\udc47 Regenerate your token_secret and paste here 1 access_token_secret = \"<Your access_token_secret will come here>\" \ud83d\udc47 Regenerate your API_key and paste here 1 API_key = \"<Your API_key will come here>\" \ud83d\udc47 Regenerate your API_key_secret and paste here 1 API_key_secret = \"<Your API_key_secret will come here>\" \ud83d\udc47ignore this line 1 #from credentials import access_token, access_token_secret, API_key, API_key_secret \u2b07 This will create an authentication object for twitter 1 auth = tweepy . OAuthHandler ( API_key , API_key_secret ) \u2b07 This will set the access token for the specific project 1 auth . set_access_token ( access_token , access_token_secret ) \u2b07 we will try to authenticate with twitter API using our authentication credentials 1 api = tweepy . API ( auth ) \u2b07 we are accessing our twitter timeline Returns the 20 most recent statuses, including retweets, posted by the authenticating user and that user\u2019s friends. This is the equivalent of /timeline/home on the Web. 1 public_tweets = api . home_timeline () \u2198 we are adding a search term 1 term = \"sony\" \u2198 this is the tweet count we want to retrieve 1 tweet_count = 5 \u2198 The results from the user timeline is stored in this variable 1 results = api . user_timeline ( id = term , count = tweet_count ) 1 print ( \"Tweets Pulled related to \" , term ) 1 Tweets Pulled related to sony 1 i = 1 \u2198 Printing the tweets using for loop 1 2 3 4 for tweet in results : print ( \"Tweet No..\" , i , \"-->\" ) print ( tweet . text ) i += 1 1 2 3 4 5 6 7 8 9 10 Tweet No.. 1 --> < tweet data 1 > Tweet No.. 2 --> < tweet data 2 > Tweet No.. 3 --> < tweet data 3 > Tweet No.. 4 --> < tweet data 4 > Tweet No.. 5 --> < tweet data 5 >","title":"Practical 8"},{"location":"IRP8/#aim-write-a-program-for-mining-twitter-to-identify-tweets-for-a-specific-period-and-identify-trends-and-named-entities","text":"","title":"Aim : Write a program for mining Twitter to identify tweets for a specific period and identify trends and named entities"},{"location":"IRP8/#importing-tweepy-to-work-with-twitter-apis","text":"1 import tweepy","title":"\u2b07 Importing tweepy to work with Twitter APIs"},{"location":"IRP8/#regenerate-your-token-and-paste-here","text":"1 access_token = \"<Your Access_Token will come here>\"","title":"\ud83d\udc47 Regenerate your token and paste here"},{"location":"IRP8/#regenerate-your-token_secret-and-paste-here","text":"1 access_token_secret = \"<Your access_token_secret will come here>\"","title":"\ud83d\udc47 Regenerate your token_secret and paste here"},{"location":"IRP8/#regenerate-your-api_key-and-paste-here","text":"1 API_key = \"<Your API_key will come here>\"","title":"\ud83d\udc47 Regenerate your API_key and paste here"},{"location":"IRP8/#regenerate-your-api_key_secret-and-paste-here","text":"1 API_key_secret = \"<Your API_key_secret will come here>\"","title":"\ud83d\udc47 Regenerate your API_key_secret and paste here"},{"location":"IRP8/#ignore-this-line","text":"1 #from credentials import access_token, access_token_secret, API_key, API_key_secret","title":"\ud83d\udc47ignore this line"},{"location":"IRP8/#this-will-create-an-authentication-object-for-twitter","text":"1 auth = tweepy . OAuthHandler ( API_key , API_key_secret )","title":"\u2b07 This will create an authentication object for twitter"},{"location":"IRP8/#this-will-set-the-access-token-for-the-specific-project","text":"1 auth . set_access_token ( access_token , access_token_secret )","title":"\u2b07 This will set the access token for the specific project"},{"location":"IRP8/#we-will-try-to-authenticate-with-twitter-api-using-our-authentication-credentials","text":"1 api = tweepy . API ( auth )","title":"\u2b07 we will try to authenticate with twitter API using our authentication credentials"},{"location":"IRP8/#we-are-accessing-our-twitter-timeline","text":"Returns the 20 most recent statuses, including retweets, posted by the authenticating user and that user\u2019s friends. This is the equivalent of /timeline/home on the Web. 1 public_tweets = api . home_timeline ()","title":"\u2b07 we are accessing our twitter timeline"},{"location":"IRP8/#we-are-adding-a-search-term","text":"1 term = \"sony\"","title":"\u2198 we are adding a search term"},{"location":"IRP8/#this-is-the-tweet-count-we-want-to-retrieve","text":"1 tweet_count = 5","title":"\u2198 this is the tweet count we want to retrieve"},{"location":"IRP8/#the-results-from-the-user-timeline-is-stored-in-this-variable","text":"1 results = api . user_timeline ( id = term , count = tweet_count ) 1 print ( \"Tweets Pulled related to \" , term ) 1 Tweets Pulled related to sony 1 i = 1","title":"\u2198 The results from the user timeline is stored in this variable"},{"location":"IRP8/#printing-the-tweets-using-for-loop","text":"1 2 3 4 for tweet in results : print ( \"Tweet No..\" , i , \"-->\" ) print ( tweet . text ) i += 1 1 2 3 4 5 6 7 8 9 10 Tweet No.. 1 --> < tweet data 1 > Tweet No.. 2 --> < tweet data 2 > Tweet No.. 3 --> < tweet data 3 > Tweet No.. 4 --> < tweet data 4 > Tweet No.. 5 --> < tweet data 5 >","title":"\u2198 Printing the tweets using for loop"},{"location":"IR_P1/","text":"IR Practical 1 Aim : Write a program to demonstrate bitwise operation. Integer Value Binary Value a 2 0010 b 4 0100 AND 0 0000 OR 6 0110 NOT(2) -3 -1100 Lshift(2) 1 0001 Rshift(2) 4 0100 Part A :Binary Bitwise Operators \u2b07 We are imporitng sys for conversion of integers to binary (this is optional). 1 import sys \u2b07 This Function is just a quick method to convert out integer into Binary (Makes it easier to understand) 1 2 def i2b ( in1 ): return bin ( int . from_bytes ( bytes ( str ( in1 ), encoding = \"utf8\" ), byteorder = sys . byteorder )) \u2b07 Taking Input for first value 1 a = int ( input ( \"enter the first value\" )) 1 enter the first value 2 \u2b07 Binary Representation of first value 1 i2b ( a ) 1 '0b110010' \u2b07 Taking input for second value 1 b = int ( input ( \"Enter the second value\" )) 1 Enter the second value 4 \u2b07 Binary Representation for second value 1 i2b ( b ) 1 '0b110100' 1 2 c1 = a & b print ( \"The Bitwise AND of a and b \\n Binary:\" , i2b ( c1 ), \" \\n Integer:\" , c1 ) 1 2 3 The Bitwise AND of a and b Binary: 0b110000 Integer: 0 1 2 c2 = a | b print ( \"The Bitwise OR of a and b is \\n Binary:\" , i2b ( c2 ), \" \\n Integer:\" , c2 ) 1 2 3 The Bitwise OR of a and b is Binary: 0b110110 Integer: 6 1 2 c3 = a ^ b print ( \"The Bitwise EXOR of a and b is \\n Binary:\" , i2b ( c3 ), \" \\n Integer:\" , c3 ) 1 2 3 The Bitwise EXOR of a and b is Binary: 0b110110 Integer: 6 1 2 c4 =~ a & 255 # Python Calculates Negation on 8bit unsigned integers. print ( \"The Bitwise NOT of a is \\n Binary:\" , i2b ( c4 ), \" \\n Integer:\" , c4 ) 1 2 3 The Bitwise NOT of a is Binary: 0b1100110011010100110010 Integer: 253 1 2 c5 =~ b & 255 print ( \"The Bitwise NOT of b is \\n Binary:\" , i2b ( c5 ), \" \\n Integer:\" , c5 ) 1 2 3 The Bitwise NOT of b is Binary: 0b1100010011010100110010 Integer: 251 1 2 c6 = a >> 1 print ( \"The Left Shift of a is \\n Binary:\" , i2b ( c6 ), \" \\n Integer:\" , c6 ) 1 2 3 The Left Shift of a is Binary: 0b110001 Integer: 1 1 2 c7 = b >> 1 print ( \"The Left Shift of b is \\n Binary:\" , i2b ( c7 ), \" \\n Integer:\" , c7 ) 1 2 3 The Left Shift of b is Binary: 0b110010 Integer: 2 1 2 c8 = a << 1 print ( \"The Right Shift of a is \\n Binary:\" , i2b ( c8 ), \" \\n Integer:\" , c8 ) 1 2 3 The Right Shift of a is Binary: 0b110100 Integer: 4 1 2 c9 = b << 1 print ( \"The Right Shift of b is \\n Binary:\" , i2b ( c9 ), \" \\n Integer:\" , c9 ) 1 2 3 The Right Shift of b is Binary: 0b111000 Integer: 8 Part B :Boolean Operation On Text \u2b07 Importing Pandas for creating dataFrame of Word occourences 1 import pandas as pd \u2b07 We are importing CountVectorizer to Convert a collection of text documents to a matrix of token counts 1 from sklearn.feature_extraction.text import CountVectorizer \u2b07 creating a variable with some sentences which can also be documents 1 2 3 4 5 6 corpus = [ 'We are doing IR practicals' , 'IR is interesting subject' , 'IR subject is a part of computer science' , 'computer science is the category of practicals' ] \u2b07 Creating an object of CountVectorizer class 1 vectorizer = CountVectorizer () \u2b07 Fit followed by transform will learn the vocabulary dictionary and return document-term matrix. 1 x = vectorizer . fit_transform ( corpus ) 1 print ( 'Fit Transform is : \\n ' , x . toarray ()) 1 2 3 4 5 Fit Transform is : [[1 0 0 1 0 1 0 0 0 1 0 0 0 1] [0 0 0 0 1 1 1 0 0 0 0 1 0 0] [0 0 1 0 0 1 1 1 1 0 1 1 0 0] [0 1 1 0 0 0 1 1 0 1 1 0 1 0]] \u2b07 Here we create a DataFrame of the above Fit Transform Matrix with headings as the individual words. 1 df = pd . DataFrame ( x . toarray (), columns = vectorizer . get_feature_names ()) 1 print ( \"Generated DataFrame is : \\n \" , df ) 1 2 3 4 5 6 7 8 9 10 11 12 Generated DataFrame is : are category computer doing interesting ir is of part practicals \\ 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 2 0 0 1 0 0 1 1 1 1 0 3 0 1 1 0 0 0 1 1 0 1 science subject the we 0 0 0 0 1 1 0 1 0 0 2 1 1 0 0 3 1 0 1 0 1 anddata = df [( df [ 'ir' ] == 1 ) & ( df [ 'practicals' ] == 1 )] 1 print ( \"Indices where both 'ir' and 'practicals' are present are:\" , anddata . index . tolist ()) 1 Indices where both 'ir' and 'practicals' are present are: [0] 1 ordata = df [( df [ 'ir' ] == 1 ) | ( df [ 'practicals' ] == 1 )] 1 print ( \"Indices where 'ir' or 'practicals' are present are:\" , ordata . index . tolist ()) 1 Indices where 'ir' or 'practicals' are present are: [0, 1, 2, 3] 1 notdata = df [( df [ 'ir' ] != 1 )] 1 print ( \"Indices where 'ir' is not are present are:\" , notdata . index . tolist ()) 1 Indices where 'ir' is not are present are: [3]","title":"Practical 1"},{"location":"IR_P1/#ir-practical-1","text":"","title":"IR Practical 1"},{"location":"IR_P1/#aim-write-a-program-to-demonstrate-bitwise-operation","text":"Integer Value Binary Value a 2 0010 b 4 0100 AND 0 0000 OR 6 0110 NOT(2) -3 -1100 Lshift(2) 1 0001 Rshift(2) 4 0100","title":"Aim : Write a program to demonstrate bitwise operation."},{"location":"IR_P1/#part-a-binary-bitwise-operators","text":"","title":"Part A :Binary Bitwise Operators"},{"location":"IR_P1/#we-are-imporitng-sys-for-conversion-of-integers-to-binary-this-is-optional","text":"1 import sys","title":"\u2b07 We are imporitng sys for conversion of integers to binary (this is optional)."},{"location":"IR_P1/#this-function-is-just-a-quick-method-to-convert-out-integer-into-binary-makes-it-easier-to-understand","text":"1 2 def i2b ( in1 ): return bin ( int . from_bytes ( bytes ( str ( in1 ), encoding = \"utf8\" ), byteorder = sys . byteorder ))","title":"\u2b07 This Function is just a quick method to convert out integer into Binary (Makes it easier to understand)"},{"location":"IR_P1/#taking-input-for-first-value","text":"1 a = int ( input ( \"enter the first value\" )) 1 enter the first value 2","title":"\u2b07 Taking Input for first value"},{"location":"IR_P1/#binary-representation-of-first-value","text":"1 i2b ( a ) 1 '0b110010'","title":"\u2b07 Binary Representation of first value"},{"location":"IR_P1/#taking-input-for-second-value","text":"1 b = int ( input ( \"Enter the second value\" )) 1 Enter the second value 4","title":"\u2b07 Taking input for second value"},{"location":"IR_P1/#binary-representation-for-second-value","text":"1 i2b ( b ) 1 '0b110100' 1 2 c1 = a & b print ( \"The Bitwise AND of a and b \\n Binary:\" , i2b ( c1 ), \" \\n Integer:\" , c1 ) 1 2 3 The Bitwise AND of a and b Binary: 0b110000 Integer: 0 1 2 c2 = a | b print ( \"The Bitwise OR of a and b is \\n Binary:\" , i2b ( c2 ), \" \\n Integer:\" , c2 ) 1 2 3 The Bitwise OR of a and b is Binary: 0b110110 Integer: 6 1 2 c3 = a ^ b print ( \"The Bitwise EXOR of a and b is \\n Binary:\" , i2b ( c3 ), \" \\n Integer:\" , c3 ) 1 2 3 The Bitwise EXOR of a and b is Binary: 0b110110 Integer: 6 1 2 c4 =~ a & 255 # Python Calculates Negation on 8bit unsigned integers. print ( \"The Bitwise NOT of a is \\n Binary:\" , i2b ( c4 ), \" \\n Integer:\" , c4 ) 1 2 3 The Bitwise NOT of a is Binary: 0b1100110011010100110010 Integer: 253 1 2 c5 =~ b & 255 print ( \"The Bitwise NOT of b is \\n Binary:\" , i2b ( c5 ), \" \\n Integer:\" , c5 ) 1 2 3 The Bitwise NOT of b is Binary: 0b1100010011010100110010 Integer: 251 1 2 c6 = a >> 1 print ( \"The Left Shift of a is \\n Binary:\" , i2b ( c6 ), \" \\n Integer:\" , c6 ) 1 2 3 The Left Shift of a is Binary: 0b110001 Integer: 1 1 2 c7 = b >> 1 print ( \"The Left Shift of b is \\n Binary:\" , i2b ( c7 ), \" \\n Integer:\" , c7 ) 1 2 3 The Left Shift of b is Binary: 0b110010 Integer: 2 1 2 c8 = a << 1 print ( \"The Right Shift of a is \\n Binary:\" , i2b ( c8 ), \" \\n Integer:\" , c8 ) 1 2 3 The Right Shift of a is Binary: 0b110100 Integer: 4 1 2 c9 = b << 1 print ( \"The Right Shift of b is \\n Binary:\" , i2b ( c9 ), \" \\n Integer:\" , c9 ) 1 2 3 The Right Shift of b is Binary: 0b111000 Integer: 8","title":"\u2b07 Binary Representation for second value"},{"location":"IR_P1/#part-b-boolean-operation-on-text","text":"","title":"Part B :Boolean Operation On Text"},{"location":"IR_P1/#importing-pandas-for-creating-dataframe-of-word-occourences","text":"1 import pandas as pd","title":"\u2b07 Importing Pandas for creating dataFrame of Word occourences"},{"location":"IR_P1/#we-are-importing-countvectorizer-to-convert-a-collection-of-text-documents-to-a-matrix-of-token-counts","text":"1 from sklearn.feature_extraction.text import CountVectorizer","title":"\u2b07 We are importing CountVectorizer to Convert a collection of text documents to a matrix of token counts"},{"location":"IR_P1/#creating-a-variable-with-some-sentences-which-can-also-be-documents","text":"1 2 3 4 5 6 corpus = [ 'We are doing IR practicals' , 'IR is interesting subject' , 'IR subject is a part of computer science' , 'computer science is the category of practicals' ]","title":"\u2b07 creating a variable with some sentences which can also be documents"},{"location":"IR_P1/#creating-an-object-of-countvectorizer-class","text":"1 vectorizer = CountVectorizer ()","title":"\u2b07 Creating an object of CountVectorizer class"},{"location":"IR_P1/#fit-followed-by-transform-will-learn-the-vocabulary-dictionary-and-return-document-term-matrix","text":"1 x = vectorizer . fit_transform ( corpus ) 1 print ( 'Fit Transform is : \\n ' , x . toarray ()) 1 2 3 4 5 Fit Transform is : [[1 0 0 1 0 1 0 0 0 1 0 0 0 1] [0 0 0 0 1 1 1 0 0 0 0 1 0 0] [0 0 1 0 0 1 1 1 1 0 1 1 0 0] [0 1 1 0 0 0 1 1 0 1 1 0 1 0]]","title":"\u2b07 Fit followed by transform will learn the vocabulary dictionary and return document-term matrix."},{"location":"IR_P1/#here-we-create-a-dataframe-of-the-above-fit-transform-matrix-with-headings-as-the-individual-words","text":"1 df = pd . DataFrame ( x . toarray (), columns = vectorizer . get_feature_names ()) 1 print ( \"Generated DataFrame is : \\n \" , df ) 1 2 3 4 5 6 7 8 9 10 11 12 Generated DataFrame is : are category computer doing interesting ir is of part practicals \\ 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 2 0 0 1 0 0 1 1 1 1 0 3 0 1 1 0 0 0 1 1 0 1 science subject the we 0 0 0 0 1 1 0 1 0 0 2 1 1 0 0 3 1 0 1 0 1 anddata = df [( df [ 'ir' ] == 1 ) & ( df [ 'practicals' ] == 1 )] 1 print ( \"Indices where both 'ir' and 'practicals' are present are:\" , anddata . index . tolist ()) 1 Indices where both 'ir' and 'practicals' are present are: [0] 1 ordata = df [( df [ 'ir' ] == 1 ) | ( df [ 'practicals' ] == 1 )] 1 print ( \"Indices where 'ir' or 'practicals' are present are:\" , ordata . index . tolist ()) 1 Indices where 'ir' or 'practicals' are present are: [0, 1, 2, 3] 1 notdata = df [( df [ 'ir' ] != 1 )] 1 print ( \"Indices where 'ir' is not are present are:\" , notdata . index . tolist ()) 1 Indices where 'ir' is not are present are: [3]","title":"\u2b07 Here we create a DataFrame of the above Fit Transform Matrix with headings as the individual words."},{"location":"genviva/","text":"What is Hadoop ? Apache Hadoop is a collection of open-source software utilities that facilitates using a network of many computers to solve problems involving massive amounts of data and computation. It provides a software framework for distributed storage and processing of big data using the MapReduce programming model. Hadoop was originally designed for computer clusters built from commodity hardware, which is still the common use. It has since also found use on clusters of higher-end hardware. All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common occurrences and should be automatically handled by the framework. The core of Apache Hadoop consists of a storage part, known as Hadoop Distributed File System (HDFS), and a processing part which is a MapReduce programming model. Hadoop splits files into large blocks and distributes them across nodes in a cluster. Components of Hadoop ? The base Apache Hadoop framework is composed of the following modules: 1. Hadoop Common \u2013 contains libraries and utilities needed by other Hadoop modules; 2. Hadoop Distributed File System (HDFS) \u2013 a distributed file-system that stores data on commodity machines, providing very high aggregate bandwidth across the cluster; 3. Hadoop YARN \u2013 (introduced in 2012) a platform responsible for managing computing resources in clusters and using them for scheduling users' applications; 4. Hadoop MapReduce \u2013 an implementation of the MapReduce programming model for large-scale data processing. 5. Hadoop Ozone \u2013 (introduced in 2020) An object store for Hadoop","title":"General"}]}